We have text and want to break it up into individual words, Natural Language Toolkit for Python (NLTK) has a powerful set of text manipulation operations,
including word tokenizing, We can also tokenize into sentences, Tokenization, especially word tokenization, is a common task after cleaning text data because it is the
first step in the process of turning the text into data we will use to construct useful features. Some pretrained NLP models (such as Googleâ€™s BERT) utilize model-specific tokenization techniques, however
word-level tokenization is still a fairly common tokenization approach before getting features from
individual words
